{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2 : Prediction Challenge\n",
    "### Keertana Chidambaram (Collaborator: Dhruval Bhatt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: all notes are for Dhruval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nlsy training set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E5011701</th>\n",
       "      <th>E5011702</th>\n",
       "      <th>E5011703</th>\n",
       "      <th>E5011704</th>\n",
       "      <th>E5011705</th>\n",
       "      <th>E5011706</th>\n",
       "      <th>E5011707</th>\n",
       "      <th>E5011708</th>\n",
       "      <th>E5011709</th>\n",
       "      <th>E5011710</th>\n",
       "      <th>...</th>\n",
       "      <th>Z9122600</th>\n",
       "      <th>Z9141400</th>\n",
       "      <th>Z9141500</th>\n",
       "      <th>Z9141600</th>\n",
       "      <th>Z9141700</th>\n",
       "      <th>Z9141800</th>\n",
       "      <th>Z9141900</th>\n",
       "      <th>Z9142000</th>\n",
       "      <th>Z9142100</th>\n",
       "      <th>diag.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>6328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7500</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>7655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>3517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>8540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   E5011701  E5011702  E5011703  E5011704  E5011705  E5011706  E5011707  \\\n",
       "0        -4        -4         2         2         2         1         1   \n",
       "1        -4        -4        -4        -4        -4        -4        -4   \n",
       "2        -4        -4        -4         2         2         4         4   \n",
       "3        -4        -4        -4         2         2         2         1   \n",
       "4        -4        -4        -4        -4        -4        -4         2   \n",
       "\n",
       "   E5011708  E5011709  E5011710  ...  Z9122600  Z9141400  Z9141500  Z9141600  \\\n",
       "0         2         2         2  ...        16        -4        -4        -4   \n",
       "1         2         2         2  ...        17      7500         0         0   \n",
       "2         2         2         2  ...        16        -4        -4        -4   \n",
       "3         1         2         2  ...        16        -4        -4        -4   \n",
       "4         2         2         2  ...        16        -4        -4        -4   \n",
       "\n",
       "   Z9141700  Z9141800  Z9141900  Z9142000  Z9142100  diag.id  \n",
       "0        -4        -4        -4        -4        -4     6328  \n",
       "1         6         0      7500         0        18      388  \n",
       "2        -4        -4        -4        -4        -4     7655  \n",
       "3        -4        -4        -4        -4        -4     3517  \n",
       "4        -4        -4        -4        -4        -4     8540  \n",
       "\n",
       "[5 rows x 4886 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7187, 4886)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unanswered Qs:\n",
    "- To include or exclude observations with missing data from the test set while building the model??\n",
    "- If included, should the model predict the 'type' of the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New learnings:\n",
    "- Dealing with missing data: treat as another feature, predict feature (mean/median/mode imputation, KNN imputation), skip feature (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- Predictor variables are mostly categorical but predicted variable is ordinal categorical\n",
    "- Error is MSE, so take predicted variable as continuous \n",
    "- Missing Ys are not needed, make an error function that accounts for all this\n",
    "- Since missing Ys not needed, predict missing Y as a -1. That way even if prediction is wrong, we still get small MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff we could do:\n",
    "- One-hot encoding for categorical data\n",
    "- Regularization\n",
    "- Remove missing data from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of available models:\n",
    "1. Regression - NO. used when Xs are continuous\n",
    "2. Classification - NO. used when predicted variables is categorical\n",
    "3. Logistic regression - NO. used when predicted variable is binary, multi-class logistic when y is categorical\n",
    "4. Gradient boosting\n",
    "5. Decision trees - works!\n",
    "6. Random forest - works!\n",
    "7. Neural networks - works!\n",
    "8. Ensemble methods - works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.32517044663977"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['U1031900'] >= 0) * 100 / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ready-made python packages for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "# OLS\n",
    "import statsmodels.api as sm\n",
    "xvars = ['bin1', 'bin2','bin3','bin4','bin5']\n",
    "X = data[xvars]\n",
    "y = data['coolness']\n",
    "result = sm.OLS(y, X).fit()\n",
    "\n",
    "# K Nearest Neighbor\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=10)\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors = 2)\n",
    "x_vars = ['X1', 'X2', 'X3']\n",
    "train_data[x_vars]\n",
    "res = model.fit(train_data[x_vars], train_data['Y'])\n",
    "print('Predicted value for (1,1,1) is:')\n",
    "print(res.predict([(0,0,0)]))\n",
    "\n",
    "# Leave one out cross-validation\n",
    "Xvars = X.values\n",
    "yvars = y.values\n",
    "N_loo = Xvars.shape[0]\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(Xvars)\n",
    "MSE_vec = np.zeros(N_loo)\n",
    "y_pred = np.zeros(N_loo)\n",
    "\n",
    "for train_index, test_index in loo.split(Xvars):\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "    LogReg = LogisticRegression(solver='newton-cg',multi_class='multinomial').fit(X_train, y_train)\n",
    "    y_pred[test_index] = LogReg.predict(X_test)\n",
    "    \n",
    "    MSE_vec[test_index] = y_test != y_pred[test_index]\n",
    "\n",
    "MSE_loo = MSE_vec.mean()\n",
    "print('test estimate MSE loocv=', MSE_loo)\n",
    "\n",
    "# K-fold CV\n",
    "Xvars = X.values\n",
    "yvars = y.values\n",
    "k = 4\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=10)\n",
    "kf.get_n_splits(Xvars)\n",
    "\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "y_pred = np.zeros(len(yvars))\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(Xvars):\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "    LogReg = LogisticRegression(solver='newton-cg',multi_class='multinomial').fit(X_train, y_train)\n",
    "    \n",
    "    y_pred[test_index] = LogReg.predict(X_test)\n",
    "\n",
    "    err = y_pred[test_index] != y_test\n",
    "    MSE_vec_kf[k_ind] = err.mean()\n",
    "    k_ind += 1\n",
    "\n",
    "MSE_kf = MSE_vec_kf.mean()\n",
    "print('test estimate MSE k-fold (k=4) =', MSE_kf)\n",
    "\n",
    "# Decision trees\n",
    "xvars = ['female', 'age', 'educ', 'dem', 'rep']\n",
    "X = data[xvars]\n",
    "y = data['biden']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=25)\n",
    "biden_tree = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5)\n",
    "biden_tree.fit(X_train, y_train)\n",
    "y_pred = biden_tree.predict(X_test)\n",
    "MSE1 = mean_squared_error(y_test, y_pred)\n",
    "print('MSE=', MSE1)\n",
    "\n",
    "# Search for best tree\n",
    "param_dist1 = {'max_depth': [3, 10],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20)}\n",
    "\n",
    "biden_tree2 = DecisionTreeRegressor()\n",
    "\n",
    "random_search1 = RandomizedSearchCV(biden_tree2, \n",
    "                                    param_distributions=param_dist1,\n",
    "                                    n_iter=100, \n",
    "                                    n_jobs=-1, \n",
    "                                    cv=5, \n",
    "                                    random_state=25,\n",
    "                                    scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search1.fit(X, y)\n",
    "print('Best estimator = ', random_search1.best_estimator_)\n",
    "print('Best tuning parameters = ', random_search1.best_params_)\n",
    "print('MSE of optimal results =', -random_search1.best_score_)\n",
    "\n",
    "# Random forest\n",
    "param_dist2 = { 'n_estimators': [10, 200],\n",
    "                'max_depth': [3, 10],\n",
    "                'min_samples_split': sp_randint(2, 20),\n",
    "                'min_samples_leaf': sp_randint(2, 20),\n",
    "                'max_features': sp_randint(1, 5)}\n",
    "\n",
    "biden_tree3 = RandomForestRegressor(bootstrap=True,oob_score=True, random_state=25)\n",
    "\n",
    "random_search2 = RandomizedSearchCV(biden_tree3, param_distributions=param_dist2, n_iter=100,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search2.fit(X, y)\n",
    "print('Best estimator = ', random_search2.best_estimator_)\n",
    "print('Best tuning parameters = ', random_search2.best_params_)\n",
    "print('MSE of optimal results =', -random_search2.best_score_)\n",
    "\n",
    "# Solution 1.c.\n",
    "forest = RandomForestClassifier(bootstrap=True, oob_score=True)\n",
    "\n",
    "param_dist2 = { 'n_estimators': sp_randint(10, 200),\n",
    "                'max_depth': sp_randint(2, 4),\n",
    "                'min_samples_split': sp_randint(2, 20),\n",
    "                'min_samples_leaf': sp_randint(2, 20),\n",
    "                'max_features': sp_randint(1, 4)}\n",
    "\n",
    "random_search2 = RandomizedSearchCV(forest, param_distributions=param_dist2, n_iter=200,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search2.fit(X, y)\n",
    "print('Best tuning parameters = ', random_search2.best_params_)\n",
    "print('MSE of optimal results =', -random_search2.best_score_)\n",
    "\n",
    "# Solution 1.d.\n",
    "svc_model = SVC(kernel='rbf')\n",
    "\n",
    "param_dist3 = { 'C': sp_uniform(loc=0.1, scale=10.0),\n",
    "                'gamma': ['scale', 'auto'],\n",
    "                'shrinking': [True, False]}\n",
    "random_search3 = RandomizedSearchCV(svc_model, param_distributions=param_dist3, n_iter=200,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search3.fit(X, y)\n",
    "print('Best tuning parameters = ', random_search3.best_params_)\n",
    "print('MSE of optimal results =', -random_search3.best_score_)\n",
    "\n",
    "# Solution 1.e.\n",
    "nn = MLPClassifier(solver='lbfgs')\n",
    "\n",
    "param_dist4 = {'hidden_layer_sizes': sp_randint(1, 100),\n",
    "                'activation': ['logistic', 'relu'],\n",
    "                'alpha': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "random_search4 = RandomizedSearchCV(nn, param_distributions=param_dist4, n_iter=200,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search4.fit(X, y)\n",
    "print('Best tuning parameters = ', random_search4.best_params_)\n",
    "print('MSE of optimal results =', -random_search4.best_score_)\n",
    "\n",
    "\n",
    "# K-fold cross validation used to find the average MSE\n",
    "def K_fold_CV(model, X, y, k = 4):\n",
    "    Xvals = X.values\n",
    "    yvals = y.values\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=10)\n",
    "    kf.get_n_splits(Xvals)\n",
    "    MSE_vec = np.zeros(k)\n",
    "    y_pred = np.zeros(len(yvals))\n",
    "\n",
    "    k_ind = int(0)\n",
    "    for train_index, test_index in kf.split(Xvals):\n",
    "        X_train, X_test = Xvals[train_index], Xvals[test_index]\n",
    "        y_train, y_test = yvals[train_index], yvals[test_index]\n",
    "        res = model.fit(X_train, y_train)\n",
    "        y_pred[test_index] = res.predict(X_test)\n",
    "        err = (y_pred[test_index] - y_test) ** 2\n",
    "        MSE_vec[k_ind] = err.mean()\n",
    "        k_ind += 1\n",
    "    \n",
    "    return MSE_vec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/nlsy training set.csv')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.index = df['diag.id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'U1031900']\n",
    "y = df['U1031900']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E5011701</th>\n",
       "      <th>E5011702</th>\n",
       "      <th>E5011703</th>\n",
       "      <th>E5011704</th>\n",
       "      <th>E5011705</th>\n",
       "      <th>E5011706</th>\n",
       "      <th>E5011707</th>\n",
       "      <th>E5011708</th>\n",
       "      <th>E5011709</th>\n",
       "      <th>E5011710</th>\n",
       "      <th>...</th>\n",
       "      <th>Z9122600</th>\n",
       "      <th>Z9141400</th>\n",
       "      <th>Z9141500</th>\n",
       "      <th>Z9141600</th>\n",
       "      <th>Z9141700</th>\n",
       "      <th>Z9141800</th>\n",
       "      <th>Z9141900</th>\n",
       "      <th>Z9142000</th>\n",
       "      <th>Z9142100</th>\n",
       "      <th>diag.id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag.id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6328</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>6328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7500</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>7655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>3517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8540</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>8540.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4885 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         E5011701  E5011702  E5011703  E5011704  E5011705  E5011706  E5011707  \\\n",
       "diag.id                                                                         \n",
       "6328           -4        -4         2         2         2       1.0       1.0   \n",
       "388            -4        -4        -4        -4        -4       2.0       1.0   \n",
       "7655           -4        -4        -4         2         2       4.0       4.0   \n",
       "3517           -4        -4        -4         2         2       2.0       1.0   \n",
       "8540           -4        -4        -4        -4        -4       2.0       2.0   \n",
       "\n",
       "         E5011708  E5011709  E5011710  ...  Z9122600  Z9141400  Z9141500  \\\n",
       "diag.id                                ...                                 \n",
       "6328          2.0       2.0       2.0  ...      16.0        -4        -4   \n",
       "388           2.0       2.0       2.0  ...      17.0      7500         0   \n",
       "7655          2.0       2.0       2.0  ...      16.0        -4        -4   \n",
       "3517          1.0       2.0       2.0  ...      16.0        -4        -4   \n",
       "8540          2.0       2.0       2.0  ...      16.0        -4        -4   \n",
       "\n",
       "         Z9141600  Z9141700  Z9141800  Z9141900  Z9142000  Z9142100  diag.id  \n",
       "diag.id                                                                       \n",
       "6328           -4        -4        -4        -4        -4        -4   6328.0  \n",
       "388             0         6         0      7500         0        18    388.0  \n",
       "7655           -4        -4        -4        -4        -4        -4   7655.0  \n",
       "3517           -4        -4        -4        -4        -4        -4   3517.0  \n",
       "8540           -4        -4        -4        -4        -4        -4   8540.0  \n",
       "\n",
       "[5 rows x 4885 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = X.where(X>=0).count().sort_values(ascending=False)/X.shape[0] #.sorted()\n",
    "impute_vars = list(counts.index[:1013])\n",
    "for col in impute_vars:\n",
    "    print(col)\n",
    "    X.loc[X[col]<0, col] = np.nan\n",
    "    X[col].fillna(list(X[col].mode())[0], inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in X.columns:\n",
    "#     new_dummies = pd.get_dummies(X[col])\n",
    "#     new_dummies.columns = [str(i) + col for i in new_dummies.columns]\n",
    "#     X = X.join(new_dummies)\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MSE(y_true, y_pred):\n",
    "    '''Calculates the Mean Squared Error given original and predicted values'''\n",
    "    y_pred[y_pred<0] = 0\n",
    "    err = (y_pred[y_true>=0] - y_true[y_true>=0]) ** 2\n",
    "    return err.mean()\n",
    "new_scorer = make_scorer(calc_MSE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.4368792528934\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(max_depth=5, min_samples_split=5, min_samples_leaf=40)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(calc_MSE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "MSE =  19.887888780513446\n",
      "params =  {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 30}\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees\n",
    "params = {'max_depth': [5, 10, 15],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "          'min_samples_leaf': [30, 40, 50, 60]}\n",
    "best_MSE = 1000\n",
    "best_params = {}\n",
    "for max_depth in params['max_depth']:\n",
    "    print(max_depth)\n",
    "    for min_samples_split in params['min_samples_split']:\n",
    "        for min_samples_leaf in params['min_samples_leaf']:\n",
    "            model = DecisionTreeRegressor(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "            model.fit(X_train,y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            new_MSE = calc_MSE(y_test, y_pred)\n",
    "            if new_MSE < best_MSE:\n",
    "                best_MSE = new_MSE\n",
    "                best_params['max_depth'] = max_depth\n",
    "                best_params['min_samples_split'] = min_samples_split\n",
    "                best_params['min_samples_leaf'] = min_samples_leaf\n",
    "                best_model = model\n",
    "print('MSE = ', best_MSE)\n",
    "print('params = ', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "10\n",
      "15\n",
      "MSE =  19.75676459710034\n",
      "params =  {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 5, 'n_estimators': 5, 'max_features': 4885}\n"
     ]
    }
   ],
   "source": [
    "# Random forest regressor\n",
    "params = {  'n_estimators': [5, 10, 15],\n",
    "            'max_depth': [7, 10, 15],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [5, 10, 25],\n",
    "            'max_features': [4000, 4885]}\n",
    "\n",
    "best_MSE = 1000\n",
    "best_params = {}\n",
    "for max_depth in params['max_depth']:\n",
    "    print(max_depth)\n",
    "    for min_samples_split in params['min_samples_split']:\n",
    "        for min_samples_leaf in params['min_samples_leaf']:\n",
    "            for n_estimators in params['n_estimators']:\n",
    "                for max_features in params['max_features']:\n",
    "                    model = RandomForestRegressor(max_depth=max_depth,\n",
    "                                                  min_samples_split=min_samples_split,\n",
    "                                                  min_samples_leaf=min_samples_leaf,\n",
    "                                                  n_estimators=n_estimators, \n",
    "                                                  max_features=max_features)\n",
    "                    model.fit(X_train,y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    new_MSE = calc_MSE(y_test, y_pred)\n",
    "                    if new_MSE < best_MSE:\n",
    "                        best_MSE = new_MSE\n",
    "                        best_params['max_depth'] = max_depth\n",
    "                        best_params['min_samples_split'] = min_samples_split\n",
    "                        best_params['min_samples_leaf'] = min_samples_leaf\n",
    "                        best_params['n_estimators'] = n_estimators\n",
    "                        best_params['max_features'] = max_features\n",
    "                        best_model = model\n",
    "print('MSE = ', best_MSE)\n",
    "print('params = ', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "params = {  'n_estimators': [5, 10, 15],\n",
    "            'max_depth': [7, 10, 15],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [5, 10, 25],\n",
    "            'max_features': [4000, 4885]}\n",
    "\n",
    "best_MSE = 1000\n",
    "best_params = {}\n",
    "for max_depth in params['max_depth']:\n",
    "    print(max_depth)\n",
    "    for min_samples_split in params['min_samples_split']:\n",
    "        for min_samples_leaf in params['min_samples_leaf']:\n",
    "            for n_estimators in params['n_estimators']:\n",
    "                for max_features in params['max_features']:\n",
    "                    model = RandomForestClassifier(max_depth=max_depth,\n",
    "                                                  min_samples_split=min_samples_split,\n",
    "                                                  min_samples_leaf=min_samples_leaf,\n",
    "                                                  n_estimators=n_estimators, \n",
    "                                                  max_features=max_features)\n",
    "                    model.fit(X_train,y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    new_MSE = calc_MSE(y_test, y_pred)\n",
    "                    if new_MSE < best_MSE:\n",
    "                        best_MSE = new_MSE\n",
    "                        best_params['max_depth'] = max_depth\n",
    "                        best_params['min_samples_split'] = min_samples_split\n",
    "                        best_params['min_samples_leaf'] = min_samples_leaf\n",
    "                        best_params['n_estimators'] = n_estimators\n",
    "                        best_params['max_features'] = max_features\n",
    "                        best_model = model\n",
    "print('MSE = ', best_MSE)\n",
    "print('params = ', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural networks\n",
    "params = { 'hidden_layer_sizes': [5, 10, 15],\n",
    "            'activation': ['logistic'],\n",
    "            'alpha': [0.9, 0.7]}\n",
    "best_MSE = 1000\n",
    "best_params = {}\n",
    "for hidden_layer_sizes in params['hidden_layer_sizes']:\n",
    "    print(hidden_layer_sizes)\n",
    "    for alpha in params['alpha']:\n",
    "        model = MLPClassifier(solver='lbfgs', \n",
    "                              activation='logistic', \n",
    "                              alpha=alpha)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        new_MSE = calc_MSE(y_test, y_pred)\n",
    "        if new_MSE < best_MSE:\n",
    "            best_MSE = new_MSE\n",
    "            best_params['max_depth'] = max_depth\n",
    "            best_params['min_samples_split'] = min_samples_split\n",
    "            best_params['min_samples_leaf'] = min_samples_leaf\n",
    "            best_model = model\n",
    "print('MSE = ', best_MSE)\n",
    "print('params = ', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "top_features = list(feature_importances.nlargest(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator =  DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=5,\n",
      "                      min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "Best tuning parameters =  {'min_samples_split': 5, 'min_samples_leaf': 5, 'max_depth': 3}\n",
      "MSE of optimal results = 22.21571616452844\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_dist1 = {'max_depth': [3, 5, 10],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [5, 10, 15, 20]}\n",
    "\n",
    "biden_tree2 = DecisionTreeRegressor()\n",
    "\n",
    "random_search1 = RandomizedSearchCV(biden_tree2, \n",
    "                                    param_distributions=param_dist1,\n",
    "                                    n_iter=100, \n",
    "                                    n_jobs=-1, \n",
    "                                    cv=5, \n",
    "                                    random_state=25,\n",
    "                                    scoring=new_scorer)\n",
    "\n",
    "random_search1.fit(X, y)\n",
    "print('Best estimator = ', random_search1.best_estimator_)\n",
    "print('Best tuning parameters = ', random_search1.best_params_)\n",
    "print('MSE of optimal results =', -random_search1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 72 is smaller than n_iter=100. Running 72 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator =  RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
      "                      max_features=1000, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=10, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=30,\n",
      "                      n_jobs=None, oob_score=True, random_state=25, verbose=0,\n",
      "                      warm_start=False)\n",
      "Best tuning parameters =  {'n_estimators': 30, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 1000, 'max_depth': 7}\n",
      "MSE of optimal results = 21.066156751180287\n"
     ]
    }
   ],
   "source": [
    "# Random forest regressor\n",
    "param_dist2 = { 'n_estimators': [10, 30],\n",
    "                'max_depth': [3, 5, 7],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [5, 10],\n",
    "                'max_features': [100, 1000, 4885]}\n",
    "\n",
    "biden_tree3 = RandomForestRegressor(bootstrap=True,oob_score=True, random_state=25)\n",
    "\n",
    "random_search2 = RandomizedSearchCV(biden_tree3, param_distributions=param_dist2, n_iter=100,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring=new_scorer)\n",
    "\n",
    "random_search2.fit(X, y)\n",
    "print('Best estimator = ', random_search2.best_estimator_)\n",
    "print('Best tuning parameters = ', random_search2.best_params_)\n",
    "print('MSE of optimal results =', -random_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 72 is smaller than n_iter=200. Running 72 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:460: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:465: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator =  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=4885, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=True, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Best tuning parameters =  {'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 4885, 'max_depth': 7}\n",
      "MSE of optimal results = 47.56041624765741\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "forest = RandomForestClassifier(bootstrap=True, oob_score=True)\n",
    "\n",
    "param_dist2 = { 'n_estimators': [10, 30],\n",
    "                'max_depth': [3, 5, 7],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [5, 10],\n",
    "                'max_features': [100, 1000, 4885]}\n",
    "\n",
    "random_search2 = RandomizedSearchCV(forest, param_distributions=param_dist2, n_iter=200,\n",
    "                                    n_jobs=4, cv=5, random_state=25, scoring=new_scorer)\n",
    "random_search2.fit(X, y)\n",
    "print('Best estimator = ', random_search2.best_estimator_)\n",
    "print('Best tuning parameters = ', random_search2.best_params_)\n",
    "print('MSE of optimal results =', -random_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural networks\n",
    "nn = MLPClassifier(solver='lbfgs')\n",
    "\n",
    "param_dist4 = {'hidden_layer_sizes': [8, 10, 12],\n",
    "                'activation': ['logistic'],\n",
    "                'alpha': [0.8, 0.7, 0.6]}\n",
    "\n",
    "random_search4 = RandomizedSearchCV(nn, param_distributions=param_dist4, n_iter=200,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring=new_scorer)\n",
    "random_search4.fit(X, y)\n",
    "print('Best tuning parameters = ', random_search4.best_params_)\n",
    "print('MSE of optimal results =', -random_search4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
