{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2 : Prediction Challenge\n",
    "### Keertana Chidambaram (Collaborator: Dhruval Bhatt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: all notes are for Dhruval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nlsy training set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E5011701</th>\n",
       "      <th>E5011702</th>\n",
       "      <th>E5011703</th>\n",
       "      <th>E5011704</th>\n",
       "      <th>E5011705</th>\n",
       "      <th>E5011706</th>\n",
       "      <th>E5011707</th>\n",
       "      <th>E5011708</th>\n",
       "      <th>E5011709</th>\n",
       "      <th>E5011710</th>\n",
       "      <th>...</th>\n",
       "      <th>Z9122600</th>\n",
       "      <th>Z9141400</th>\n",
       "      <th>Z9141500</th>\n",
       "      <th>Z9141600</th>\n",
       "      <th>Z9141700</th>\n",
       "      <th>Z9141800</th>\n",
       "      <th>Z9141900</th>\n",
       "      <th>Z9142000</th>\n",
       "      <th>Z9142100</th>\n",
       "      <th>diag.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>6328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7500</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>7655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>3517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>8540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   E5011701  E5011702  E5011703  E5011704  E5011705  E5011706  E5011707  \\\n",
       "0        -4        -4         2         2         2         1         1   \n",
       "1        -4        -4        -4        -4        -4        -4        -4   \n",
       "2        -4        -4        -4         2         2         4         4   \n",
       "3        -4        -4        -4         2         2         2         1   \n",
       "4        -4        -4        -4        -4        -4        -4         2   \n",
       "\n",
       "   E5011708  E5011709  E5011710  ...  Z9122600  Z9141400  Z9141500  Z9141600  \\\n",
       "0         2         2         2  ...        16        -4        -4        -4   \n",
       "1         2         2         2  ...        17      7500         0         0   \n",
       "2         2         2         2  ...        16        -4        -4        -4   \n",
       "3         1         2         2  ...        16        -4        -4        -4   \n",
       "4         2         2         2  ...        16        -4        -4        -4   \n",
       "\n",
       "   Z9141700  Z9141800  Z9141900  Z9142000  Z9142100  diag.id  \n",
       "0        -4        -4        -4        -4        -4     6328  \n",
       "1         6         0      7500         0        18      388  \n",
       "2        -4        -4        -4        -4        -4     7655  \n",
       "3        -4        -4        -4        -4        -4     3517  \n",
       "4        -4        -4        -4        -4        -4     8540  \n",
       "\n",
       "[5 rows x 4886 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7187, 4886)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unanswered Qs:\n",
    "- To include or exclude observations with missing data from the test set while building the model??\n",
    "- If included, should the model predict the 'type' of the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New learnings:\n",
    "- Dealing with missing data: treat as another feature, predict feature (mean/median/mode imputation, KNN imputation), skip feature (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- Predictor variables are mostly categorical but predicted variable is ordinal categorical\n",
    "- Error is MSE, so take predicted variable as continuous \n",
    "- Missing Ys are not needed, make an error function that accounts for all this\n",
    "- Since missing Ys not needed, predict missing Y as a -1. That way even if prediction is wrong, we still get small MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff we could do:\n",
    "- One-hot encoding for categorical data\n",
    "- Regularization\n",
    "- Remove missing data from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MSE(y, y_hat):\n",
    "    '''Calculates the Mean Squared Error given original and predicted values'''\n",
    "    y_new = y[y>=0]\n",
    "    y_hat_new = y_hat[y>=0]\n",
    "    err = sum((y_hat[y>=0] - y[y>=0]) ** 2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of available models:\n",
    "1. Regression - NO. used when Xs are continuous\n",
    "2. Classification - NO. used when predicted variables is categorical\n",
    "3. Logistic regression - NO. used when predicted variable is binary, multi-class logistic when y is categorical\n",
    "4. Decision trees - works!\n",
    "5. Random forest - works!\n",
    "6. Neural networks - works!\n",
    "7. Ensemble methods - works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.32517044663977"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['U1031900'] >= 0) * 100 / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ready-made python packages for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "# OLS\n",
    "import statsmodels.api as sm\n",
    "xvars = ['bin1', 'bin2','bin3','bin4','bin5']\n",
    "X = data[xvars]\n",
    "y = data['coolness']\n",
    "result = sm.OLS(y, X).fit()\n",
    "\n",
    "# K Nearest Neighbor\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=10)\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors = 2)\n",
    "x_vars = ['X1', 'X2', 'X3']\n",
    "train_data[x_vars]\n",
    "res = model.fit(train_data[x_vars], train_data['Y'])\n",
    "print('Predicted value for (1,1,1) is:')\n",
    "print(res.predict([(0,0,0)]))\n",
    "\n",
    "# Leave one out cross-validation\n",
    "Xvars = X.values\n",
    "yvars = y.values\n",
    "N_loo = Xvars.shape[0]\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(Xvars)\n",
    "MSE_vec = np.zeros(N_loo)\n",
    "y_pred = np.zeros(N_loo)\n",
    "\n",
    "for train_index, test_index in loo.split(Xvars):\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "    LogReg = LogisticRegression(solver='newton-cg',multi_class='multinomial').fit(X_train, y_train)\n",
    "    y_pred[test_index] = LogReg.predict(X_test)\n",
    "    \n",
    "    MSE_vec[test_index] = y_test != y_pred[test_index]\n",
    "\n",
    "MSE_loo = MSE_vec.mean()\n",
    "print('test estimate MSE loocv=', MSE_loo)\n",
    "\n",
    "# K-fold CV\n",
    "Xvars = X.values\n",
    "yvars = y.values\n",
    "k = 4\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=10)\n",
    "kf.get_n_splits(Xvars)\n",
    "\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "y_pred = np.zeros(len(yvars))\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(Xvars):\n",
    "    X_train, X_test = Xvars[train_index], Xvars[test_index]\n",
    "    y_train, y_test = yvars[train_index], yvars[test_index]\n",
    "    LogReg = LogisticRegression(solver='newton-cg',multi_class='multinomial').fit(X_train, y_train)\n",
    "    \n",
    "    y_pred[test_index] = LogReg.predict(X_test)\n",
    "\n",
    "    err = y_pred[test_index] != y_test\n",
    "    MSE_vec_kf[k_ind] = err.mean()\n",
    "    k_ind += 1\n",
    "\n",
    "MSE_kf = MSE_vec_kf.mean()\n",
    "print('test estimate MSE k-fold (k=4) =', MSE_kf)\n",
    "\n",
    "# Decision trees\n",
    "xvars = ['female', 'age', 'educ', 'dem', 'rep']\n",
    "X = data[xvars]\n",
    "y = data['biden']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=25)\n",
    "biden_tree = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5)\n",
    "biden_tree.fit(X_train, y_train)\n",
    "y_pred = biden_tree.predict(X_test)\n",
    "MSE1 = mean_squared_error(y_test, y_pred)\n",
    "print('MSE=', MSE1)\n",
    "\n",
    "# Search for best tree\n",
    "param_dist1 = {'max_depth': [3, 10],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20)}\n",
    "\n",
    "biden_tree2 = DecisionTreeRegressor()\n",
    "\n",
    "random_search1 = RandomizedSearchCV(biden_tree2, \n",
    "                                    param_distributions=param_dist1,\n",
    "                                    n_iter=100, \n",
    "                                    n_jobs=-1, \n",
    "                                    cv=5, \n",
    "                                    random_state=25,\n",
    "                                    scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search1.fit(X, y)\n",
    "print('Best estimator = ', random_search1.best_estimator_)\n",
    "print('Best tuning parameters = ', random_search1.best_params_)\n",
    "print('MSE of optimal results =', -random_search1.best_score_)\n",
    "\n",
    "# Random forest\n",
    "param_dist2 = { 'n_estimators': [10, 200],\n",
    "                'max_depth': [3, 10],\n",
    "                'min_samples_split': sp_randint(2, 20),\n",
    "                'min_samples_leaf': sp_randint(2, 20),\n",
    "                'max_features': sp_randint(1, 5)}\n",
    "\n",
    "biden_tree3 = RandomForestRegressor(bootstrap=True,oob_score=True, random_state=25)\n",
    "\n",
    "random_search2 = RandomizedSearchCV(biden_tree3, param_distributions=param_dist2, n_iter=100,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search2.fit(X, y)\n",
    "print('Best estimator = ', random_search2.best_estimator_)\n",
    "print('Best tuning parameters = ', random_search2.best_params_)\n",
    "print('MSE of optimal results =', -random_search2.best_score_)\n",
    "\n",
    "# Solution 1.c.\n",
    "forest = RandomForestClassifier(bootstrap=True, oob_score=True)\n",
    "\n",
    "param_dist2 = { 'n_estimators': sp_randint(10, 200),\n",
    "                'max_depth': sp_randint(2, 4),\n",
    "                'min_samples_split': sp_randint(2, 20),\n",
    "                'min_samples_leaf': sp_randint(2, 20),\n",
    "                'max_features': sp_randint(1, 4)}\n",
    "\n",
    "random_search2 = RandomizedSearchCV(forest, param_distributions=param_dist2, n_iter=200,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search2.fit(X, y)\n",
    "print('Best tuning parameters = ', random_search2.best_params_)\n",
    "print('MSE of optimal results =', -random_search2.best_score_)\n",
    "\n",
    "# Solution 1.d.\n",
    "svc_model = SVC(kernel='rbf')\n",
    "\n",
    "param_dist3 = { 'C': sp_uniform(loc=0.1, scale=10.0),\n",
    "                'gamma': ['scale', 'auto'],\n",
    "                'shrinking': [True, False]}\n",
    "random_search3 = RandomizedSearchCV(svc_model, param_distributions=param_dist3, n_iter=200,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search3.fit(X, y)\n",
    "print('Best tuning parameters = ', random_search3.best_params_)\n",
    "print('MSE of optimal results =', -random_search3.best_score_)\n",
    "\n",
    "# Solution 1.e.\n",
    "nn = MLPClassifier(solver='lbfgs')\n",
    "\n",
    "param_dist4 = {'hidden_layer_sizes': sp_randint(1, 100),\n",
    "                'activation': ['logistic', 'relu'],\n",
    "                'alpha': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "random_search4 = RandomizedSearchCV(nn, param_distributions=param_dist4, n_iter=200,\n",
    "                                    n_jobs=-1, cv=5, random_state=25, scoring='neg_mean_squared_error')\n",
    "random_search4.fit(X, y)\n",
    "print('Best tuning parameters = ', random_search4.best_params_)\n",
    "print('MSE of optimal results =', -random_search4.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
