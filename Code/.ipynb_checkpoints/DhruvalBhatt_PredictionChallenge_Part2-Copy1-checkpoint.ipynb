{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Build a Predictor\n",
    "## Dhruval Bhatt (Collaborated with Keertana Chidambaram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions from assignment:\n",
    "\n",
    "Build a predictor . Once you have built a predictor, you should use the test data set to submit a\n",
    "csv file on canvas. That csv file should only have two columns: diag_id, y_hat.\n",
    "\n",
    "y_hat = drinks per day = 'U1031900'\n",
    "diag_id = 'diag.id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Set (7187, 4887)\n",
      "Size of Test Set (1797, 4886)\n",
      "Size of Training Set after Removing Col 1 (7187, 4886)\n",
      "Size of Test Set after Removing Col 1 (1797, 4885)\n"
     ]
    }
   ],
   "source": [
    "# Load the data given\n",
    "\n",
    "train_df = pd.read_csv('../Data/nlsy training set.csv')\n",
    "test_df = pd.read_csv('../Data/nlsy test set.csv')\n",
    "\n",
    "print(\"Size of Training Set\", train_df.shape)\n",
    "print(\"Size of Test Set\", test_df.shape)\n",
    "\n",
    "train_df.drop(train_df.columns[[0]], axis=1, inplace=True)  #remove unnamed column that is the repeat of id column in train\n",
    "test_df.drop(test_df.columns[[0]], axis=1, inplace=True)#remove unnamed column that is the repeat of id column in test\n",
    "\n",
    "print(\"Size of Training Set after Removing Col 1\", train_df.shape)\n",
    "print(\"Size of Test Set after Removing Col 1\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index('diag.id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that have missing values for the target data\n",
    "\n",
    "train_sub = train_df[train_df['U1031900'] >= 0] #subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df.loc[:, train_df.columns != 'U1031900']\n",
    "print(\"Size of Training Set X variables\", train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df['U1031900']\n",
    "print(\"Size of Training Set y variables\", train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in train_X.columns:\n",
    "#     missing_num = col.where(df < 0).count()\n",
    "#     tot = len(col)\n",
    "#     if (missing_num/tot*100 < 70):\n",
    "#         mode = col.mode()\n",
    "#         col[col < 0 ] = mode \n",
    "        \n",
    "#     new_cols = list(new_dummies.columns)\n",
    "#     new_cols = [str(i) + col for i in new_cols]\n",
    "#     new_dummies.columns = new_cols\n",
    "#     train_X = train_X.join(new_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in train_X.columns:\n",
    "#     new_dummies = pd.get_dummies(train_X[col])\n",
    "#     new_cols = list(new_dummies.columns)\n",
    "#     new_cols = [str(i) + col for i in new_cols]\n",
    "#     new_dummies.columns = new_cols\n",
    "#     train_X = train_X.join(new_dummies)\n",
    "\n",
    "# train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import make_scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "model_1 = tree.DecisionTreeClassifier()\n",
    "model_1.fit(X_train, y_train)\n",
    "pred_1 = model_1.predict(X_test)\n",
    "mse_1 = mean_squared_error(y_test, pred_1)\n",
    "print('MSE: %f' % mse_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index= X_train.columns)\n",
    "#feat_importances.nlargest(10).plot(kind='barh')\n",
    "#plt.show()\n",
    "\n",
    "selected_features_1 = list(feat_importances.nlargest(2000).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree with Selected (Just kept the top 2000 predictors)\n",
    "\n",
    "X_train_sel = X_train.filter(selected_features_1)\n",
    "X_test_sel = X_test.filter(selected_features_1)\n",
    "\n",
    "model_2 = tree.DecisionTreeClassifier()\n",
    "model_2.fit(X_train_sel, y_train)\n",
    "pred_2 = model_2.predict(X_test_sel)\n",
    "mse_2 = mean_squared_error(y_test, pred_2)\n",
    "print('MSE: %f' % mse_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Decision Tree\n",
    "\n",
    "model_3 = RandomForestClassifier()\n",
    "model_3.fit(X_train, y_train)\n",
    "pred_3 = model_3.predict(X_test)\n",
    "mse_3 = mean_squared_error(y_test, pred_3)\n",
    "print('MSE: %f' % mse_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Missing Variables\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "t_X_train = X_train\n",
    "t_X_train[t_X_train < 0] = 999\n",
    "t_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_columns = list(t_X_train.columns)\n",
    "cat_columns_idx = [t_X_train.columns.get_loc(col) \n",
    "                   for col in cat_columns]\n",
    "ohe = OneHotEncoder(categorical_features=cat_columns_idx, \n",
    "                    sparse=False, handle_unknown=\"ignore\")\n",
    "df_processed_np = ohe.fit(t_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = \n",
    "pd.get_dummies(X_train)#, prefix_sep='_', drop_first=True)\n",
    "#X_train['E5011701']\n",
    "#pd.get_dummies(X_train['E5011701'])#, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\"model\": [\"Decision Tree\", \"Decision Tree Selected\", \"Decision Tree Tuned\", \"Random Forest\", \"Random Forest Tuned\"],\n",
    "                   \"MSE\": [mse_1, mse_2, \"NA for Now\", mse_3, \"NA for Now\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MSE(y_true, y_pred):\n",
    "    '''Calculates the Mean Squared Error given original and predicted values'''\n",
    "    y_pred[y_pred<0] = 0\n",
    "    err = (y_pred[y_true>=0] - y_true[y_true>=0]) ** 2\n",
    "    return err.mean()\n",
    "new_scorer = make_scorer(calc_MSE, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XgBoost\n",
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB Regressor\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)\n",
    "yhat = np.around(preds)\n",
    "calc_MSE(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB Classifier\n",
    "\n",
    "clf = xgb.XGBClassifier(objective='multi:softmax', n_estimators = 2, max_depth  = 2)\n",
    "# train1 = clf.predict_proba(train_data)\n",
    "# test1 = clf.predict_proba(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_c = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yhat_c = np.around(preds)\n",
    "calc_MSE(y_test, preds_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = pd.DataFrame(X_test.index)\n",
    "predsc = pd.DataFrame(preds_c)\n",
    "df = pd.concat([diag, predsc], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
